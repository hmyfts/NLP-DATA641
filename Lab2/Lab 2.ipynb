{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c329235",
   "metadata": {},
   "source": [
    "# DATA 641 - Lab 2\n",
    "## Homayoon Fotros\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414f225",
   "metadata": {},
   "source": [
    "## Exercise 1 {-}\n",
    "**Translation / Back-translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18868714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from BackTranslation import BackTranslation as BkTrans\n",
    "\n",
    "trans = BkTrans()\n",
    "\n",
    "## To Spanish\n",
    "result = trans.translate('coffee', src='en', tmp='es')\n",
    "result.tran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbbb38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To French\n",
    "result2 = trans.translate('coffee', src='en', tmp='fr')\n",
    "result2.tran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0871650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kaffee'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To German\n",
    "result3 = trans.translate('coffee', src='en', tmp='de')\n",
    "result3.tran_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba4421",
   "metadata": {},
   "source": [
    "## Exercise 2 {-}\n",
    "**HTML Parsing and Cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68785d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df763cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: <title>datetime - How to get the current time in Python - Stack Overflow</title> \n",
      "\n",
      "Question: \n",
      " What is the module/method used to get the current time?\n"
     ]
    }
   ],
   "source": [
    "## Part (a) - Parsing the question on Stack Overflow\n",
    "myurl = \"https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python\"\n",
    "\n",
    "html = urlopen(myurl).read()\n",
    "\n",
    "soupified = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "question = soupified.find(\"div\", {\"class\": \"question\"})\n",
    "\n",
    "questiontext = question.find(\"div\", {\"class\": \"s-prose js-post-body\"})\n",
    "\n",
    "print('Page Title:' , soupified.title, '\\n')\n",
    "print(\"Question: \\n\", questiontext.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f11f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part (b)  - Downloding COVID data set\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "101d5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zois_dataset.xlsx', <http.client.HTTPMessage at 0x24308df8460>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zois_url = \"https://zoisboukouvalas.github.io/Code.html\"\n",
    "zois_html = urlopen(zois_url).read()\n",
    "zois_soup = BeautifulSoup(zois_html, 'html.parser')\n",
    "\n",
    "dt_cls = zois_soup.find_all(\"a\") ## parsing all <a> placeholders\n",
    "\n",
    "lnk = []\n",
    "for link in dt_cls: ## parsing all the links\n",
    "    if(link.get('href')!=None):\n",
    "        lnk.append(link.get('href'))\n",
    "        \n",
    "urls_zois = [item for item in lnk if item.find('http')==0] ## filtering out links not starting with http\n",
    "\n",
    "xls_zois = [item for item in urls_zois if item.find('xls')!=-1] ## locating the download link with .xls suffix\n",
    "\n",
    "urllib.request.urlretrieve(xls_zois[0], \"zois_dataset.xlsx\") ## Downloading the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349ee71",
   "metadata": {},
   "source": [
    "## Exercise 3 {-}\n",
    "**Extracting Text from PDF Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdefb6",
   "metadata": {},
   "source": [
    "Difficulties of Extracting from PDF files\n",
    "\n",
    "\n",
    "* Read/Copy Protection\n",
    "\n",
    "* Characters and Text out of the page (Off-page Text)\n",
    "\n",
    "* Invisible or hardly-visible Text\n",
    "\n",
    "* Kerning-related issues (Extra spaces within and between words)\n",
    "\n",
    "* Spaces removed after extraction\n",
    "\n",
    "* Embedded fonts (subfonts and code maps)\n",
    "\n",
    "* Word and Paragraph detection (also ordering)\n",
    "\n",
    "* Detecting images and other layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093ae7e",
   "metadata": {},
   "source": [
    "---\n",
    "**PDF Extraction / Working On the Corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ae710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69a5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Simple PDF File  This is a small demonstration .pdf file -  just for use in the Virtual Mechanics tutorials. More text. And more  text. And more text. And more text. And more text.  And more text. And more text. And more text. And more text. And more  text. And more text. Boring, zzzzz. And more text. And more text. And  more text. And more text. And more text. And more text. And more text.  And more text. And more text.  And more text. And more text. And more text. And more text. And more  text. And more text. And more text. Even more. Continued on page 2 ...\n"
     ]
    }
   ],
   "source": [
    "file_var = open('sample.pdf','rb')\n",
    "\n",
    "my_file = PdfFileReader(file_var)\n",
    "pg1 = my_file.getPage(0)\n",
    "txt = pg1.extractText()\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441fd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_var.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae03ac",
   "metadata": {},
   "source": [
    "## Exercise 4 {-}\n",
    "**Text Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59acbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866551f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a627b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run 4 times !!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lower-case corpus\n",
    "corpus_lower = corpus.lower()\n",
    "corpus_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e940ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removing digits, punctuations, and trimming white-spaces\n",
    "corpus_no_dig = re.sub('\\d+[ ]', '', corpus_lower) ## remove digits\n",
    "corpus_rem_punc = (' '.join(word.strip(string.punctuation) for word in corpus_no_dig.split())) ## remove punctuations\n",
    "corpus_clean = re.sub('\\s+', ' ',corpus_rem_punc).strip() ## remove extra white-spaces\n",
    "\n",
    "corpus_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60f40287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need finalize demo corpus used notebook done soon done ending month notebook run times'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenizing Corpus and Removing Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "corpus_token = word_tokenize(corpus_clean)\n",
    "\n",
    "stopw = stopwords.words('english')\n",
    "corp_no_stop = ' '.join(word for word in corpus_token if word not in stopw)\n",
    "\n",
    "corp_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9e87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need final demo corpu use notebook done soon done end month notebook run time'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "ps = PorterStemmer() ## Porter Stemmer\n",
    "\n",
    "corpus_stemmed = [ps.stem(word) for word in word_tokenize(corp_no_stop)]\n",
    "' '.join(corpus_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66421d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need finalize demo corpus used notebook done soon done ending month notebook run times'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmentizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [lemmatizer.lemmatize(word,pos='a') for word in word_tokenize(corp_no_stop)]\n",
    "' '.join(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
